# ğŸ“§ Email Spam Classifier  
*Because your inbox deserves some peace of mind!* ğŸš« (No more â€œYou won a free iPhoneâ€ emails )  

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/ML-Naive%20Bayes-orange?logo=scikitlearn" />
  <img src="https://img.shields.io/badge/Accuracy-97.74%25-success?logo=github" />
  <img src="https://img.shields.io/badge/Spam-Hunter-red?logo=mailchimp" />
</p>  

---

## ğŸ—‚ï¸ Project Structure  
ğŸ“ **`BayesClassifier.ipynb`** â†’ Data Preparation Notebook  
- ğŸ“š Imports: `pandas`, `nltk`, `matplotlib`, `numpy`  
- ğŸ“¥ Load spam/ham emails from directories  
- ğŸ§¹ Clean & preprocess: remove empties, lowercase, tokenize, remove stopwords, stem words  
- ğŸ”¬ EDA (Exploratory Data Analysis):  
  - ğŸ“Š Spam vs Ham distribution  
  - ğŸ”  Word frequency analysis  
  - â˜ï¸ Word clouds  

---

## ğŸ” Example Outputs  
Spam/Ham Distribution:  
<div center>
<img width="486" height="394" src="https://github.com/user-attachments/assets/5e075b49-1848-4dde-b320-fcc79f78d98b" />  
</div>
Word Cloud:  
<img width="486" height="500" src="https://github.com/user-attachments/assets/48b154c0-3671-4901-a472-bfd563492c99" />  
 

---

## ğŸ¤– Naive Bayes Training  
- âš™ï¸ **Setup**: constants (vocab size = `2500`), file paths  
- ğŸ—‚ï¸ **Data Loading**: sparse training/test â†’ dense DataFrame  
- ğŸ§® **Model Training**:  
  - `P(Spam)` & `P(Ham)` priors  
  - Word counts per category  
  - `P(Token|Spam)`, `P(Token|Ham)` with Laplace smoothing (to avoid zero probs ğŸ¤Œ)  
- ğŸ“¤ **Export**: probability vectors + prepared test set  

**ğŸ¯ Output:** Model ready to say *â€œSpam detected, bhai!â€* ğŸš”  

---

## ğŸ§ª Testing the Model  
<img width="610" height="633" src="https://github.com/user-attachments/assets/4bf988a6-ab57-40b2-876d-af9c68dc4c36" />  

Steps:  
1. Load test features, labels, and token probs  
2. Compute joint log-probs (spam vs ham)  
3. Apply prior (0.3116)  
4. Predict â†’ higher log-prob wins ğŸ†  
5. Accuracy check â†’ âœ… `97.74%` (1685 correct / 39 wrong)  

ğŸ“Š Bonus: Scatter plot with decision boundary included!  

---

## ğŸ“ˆ Model Performance  
| Metric      | Score   |
|-------------|---------|
| ğŸ¯ Accuracy | **95.46%** |
| âœ… Precision | **99.17%** |
| ğŸ” Recall   | **86.46%** |
| âš–ï¸ F1-Score | **92.38%** |

> ğŸ’¡ *High precision = no false alarms, so legit mails from your crush wonâ€™t land in spam ğŸ˜*  

---

## âš™ï¸ Technical Details  
- ğŸ“‘ **Dataset:** 5,796 emails (70% train / 30% test)  
- ğŸ”¤ **Features:** 102,694 unique words (after stopword removal)  
- ğŸ¤“ **Algorithm:** Multinomial Naive Bayes + Count Vectorization  

### ğŸ’ª Key Strength  
- **Precision 99.17%** â†’ Fake lottery emails: *busted* âœ…  
- Real emails: safe ğŸ›¡ï¸  

---

## ğŸ–¼ï¸ Full Model Diagram  
<img width="845" height="567" src="https://github.com/user-attachments/assets/b71c89d7-4566-4016-9404-711171eb3c13" />  

---
## âœ¨ Credits  
Built with â¤ï¸, Python ğŸ, and fueled by 1000+ spam emails promising free Bitcoin ğŸ˜….  

---
